# MANA ğŸ”¬

**Molecular Architecture for Near-infrared Absorbers**

A deep learning framework for predicting photophysical properties of photosensitizers using equivariant graph neural networks. MANA predicts absorption wavelengths (Î»_max), fluorescence properties, and singlet oxygen quantum yields (Î¦_Î”) in solvent-aware environments.

## ğŸ¯ Overview

MANA is a multi-task neural network architecture built on the PaiNN (Polarizable Atom Interaction Neural Network) backbone. It processes molecular structures and solvent information to predict key photophysical properties relevant for applications like photodynamic therapy (PDT) and near-infrared imaging.

**Key Features:**
- **E(3)-equivariant** architecture respecting physical symmetries
- **Solvent-aware** predictions accounting for solvatochromic effects
- **Multi-phase training** strategy with progressive fine-tuning
- **3D conformer generation** from SMILES strings
- Predicts Î»_max (absorption), fluorescence wavelengths, and Î¦_Î” quantum yields

## ğŸ—ï¸ Architecture

MANA uses a dual-stream architecture:

```
Solute Molecule â†’ Embedding â†’ PaiNN Layers â†’ Global Pooling â†˜
                                                                â†’ Interaction â†’ Task Heads
Solvent Shell   â†’ Embedding â†’ PaiNN Layers â†’ Global Pooling â†—                   â”œâ”€ Î»_max
                                                                                â””â”€ Î¦_Î”
```

**Core Components:**
- **Embedding Layer**: Converts atom types to learnable vectors (118 atom types)
- **Radial Basis Functions (RBF)**: Encodes distance information using Gaussian RBFs
- **PaiNN Layers**: 4 stacked equivariant message-passing layers (128-dim hidden)
- **Task Heads**: Specialized prediction heads for different photophysical properties

## ğŸ“Š Training Strategy

MANA uses a **3-phase training approach**:

1. **Phase 1 - Absorption (Î»_max)**: Train backbone and Î»_max head on absorption data
2. **Phase 2 - Fluorescence**: Fine-tune with fluorescence emission data
3. **Phase 3 - Quantum Yield (Î¦_Î”)**: Fine-tune phi head with optional backbone freezing

Each phase supports:
- Molecular ID-based splitting (prevents conformer leakage)
- Early stopping with validation monitoring
- Learning rate scheduling (ReduceLROnPlateau)
- Loss component tracking

## ğŸš€ Installation

### Requirements
```bash
# Core dependencies
torch>=2.0.0
torch-geometric>=2.3.0
rdkit>=2023.3.1
h5py>=3.8.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
scipy>=1.10.0
tqdm>=4.65.0

# Optional for visualization
graphviz>=0.20.0
```

### Setup
```bash
git clone https://github.com/squid2010/MANA.git
cd MANA
pip install -r requirements.txt  # Create this from dependencies above
```

## ğŸ“– Usage

### Training

```python
from scripts.train import train_phase
from pathlib import Path

# Phase 1: Absorption wavelength
hyperparams_p1 = {
    "tasks": ["lambda"],
    "max_epochs": 200,
    "learning_rate": 1e-3,
    "weight_decay": 1e-4,
    "early_stopping_patience": 30,
}

train_phase(
    phase_name="Phase1_Absorption",
    hyperparams=hyperparams_p1,
    dataset_path="data/lambda/lambda_only_data.h5",
    save_dir="models/phase1",
)

# Phase 2: Fluorescence (load Phase 1 weights)
hyperparams_p2 = {
    "tasks": ["lambda", "fluorescence"],
    "max_epochs": 150,
    "learning_rate": 5e-5,
    "weight_decay": 5e-4,
    "early_stopping_patience": 30,
}

train_phase(
    phase_name="Phase2_Fluorescence", 
    hyperparams=hyperparams_p2,
    dataset_path="data/phi/phidelta_data.h5",
    save_dir="models/phase2",
    load_path="models/phase1/best_model.pth",
)
```

### Evaluation

```python
from scripts.evaluation.evaluate import run_inference, generate_report

# Run inference on test set
predictions = run_inference(
    model_path="models/phase2/best_model.pth",
    dataset_path="data/test_data.h5",
    tasks=["lambda", "phi"],
)

# Generate evaluation report with plots
generate_report(predictions, output_dir="results/evaluation")
```

### Molecular Screening

```python
from scripts.screening.screen import screen_molecules

# Screen candidate molecules from SMILES
candidates = [
    "c1ccc2c(c1)c1ccccc1n2CCO",  # Example BODIPY-like structure
    "c1ccc2c(c1)sc1ccccc12",      # Thioxanthene derivative
]

results = screen_molecules(
    smiles_list=candidates,
    solvents=["water", "ethanol", "chloroform"],
    model_path="models/phase2/best_model.pth",
    output_path="results/screening_results.h5",
)
```

## ğŸ“ Project Structure

```
MANA/
â”œâ”€â”€ data/                      # Dataset storage (HDF5 files)
â”œâ”€â”€ img/                       # Figures and visualizations
â”œâ”€â”€ models/                    # Trained model checkpoints
â”œâ”€â”€ notebooks/                 # Jupyter/Colab training notebooks
â”œâ”€â”€ results/                   # Evaluation outputs and plots
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data/                  # Dataset construction
â”‚   â”‚   â”œâ”€â”€ build_phi_dataset.py
â”‚   â”‚   â”œâ”€â”€ build_pretrain_dataset.py
â”‚   â”‚   â””â”€â”€ dataset.py         # DatasetConstructor class
â”‚   â”œâ”€â”€ evaluation/            # Model evaluation
â”‚   â”‚   â”œâ”€â”€ evaluate.py        # Main evaluation script
â”‚   â”‚   â””â”€â”€ trained_vs_untrained.py
â”‚   â”œâ”€â”€ miscellaneous/         # Utilities
â”‚   â”‚   â”œâ”€â”€ make_model_image.py
â”‚   â”‚   â””â”€â”€ visualize_mol.py
â”‚   â”œâ”€â”€ model/                 # Neural network architecture
â”‚   â”‚   â”œâ”€â”€ mana_model.py      # MANA model definition
â”‚   â”‚   â””â”€â”€ training_engine.py # Training loop
â”‚   â”œâ”€â”€ screening/             # Virtual screening tools
â”‚   â”‚   â”œâ”€â”€ screen.py
â”‚   â”‚   â””â”€â”€ analyze_results.py
â”‚   â””â”€â”€ train.py               # Training pipeline
â””â”€â”€ notes/                     # Development notes
```

## ğŸ“ˆ Performance Metrics

MANA evaluates performance using:
- **Î»_max**: RMSE, MAE, RÂ² correlation
- **Î¦_Î”**: Accuracy (binned), Kendall's Ï„ ranking correlation
- **Solvatochromic shifts**: Prediction of Î»_vacuum vs Î»_solvated
- **Combined utility**: Gaussian(Î») Ã— clipped(Î¦_Î”) for NIR scoring

## ğŸ”¬ Datasets

MANA supports HDF5 datasets with the following structure:

```python
# Required fields
- smiles: bytes         # SMILES strings
- positions: float32    # 3D coordinates (N, max_atoms, 3)
- atomic_numbers: int32 # Atomic numbers (N, max_atoms)
- lambda_abs: float32   # Absorption wavelength (nm)
- lambda_flu: float32   # Fluorescence wavelength (nm, optional)
- phi_delta: float32    # Quantum yield (0-1, optional)
- solvent_smiles: bytes # Solvent SMILES (optional)
- mol_id: int32         # Molecule identifier for splitting
```

### Building Datasets

```bash
# Build absorption dataset
python scripts/data/build_pretrain_dataset.py \
    --input data/raw/absorption_data.csv \
    --output data/lambda/lambda_only_data.h5

# Build quantum yield dataset  
python scripts/data/build_phi_dataset.py \
    --input data/raw/wilkinson_dataset.csv \
    --output data/phi/phidelta_data.h5 \
    --num-conformers 10
```

## ğŸ¨ Visualization

Generate architecture diagrams:
```bash
python scripts/miscellaneous/make_model_image.py \
    --out img/mana_architecture.png \
    --format png \
    --layers 4 \
    --nodes 6
```

Visualize molecular predictions:
```bash
python scripts/miscellaneous/visualize_mol.py \
    --smiles "c1ccc2c(c1)sc1ccccc12" \
    --model models/phase2/best_model.pth
```

## ğŸ¤ Contributing

This project was developed as part of a research initiative. Contributions, issues, and feature requests are welcome!

## ğŸ“„ License

[Specify your license here]

## ğŸ™ Acknowledgments

- Built using PyTorch Geometric and RDKit
- PaiNN architecture inspired by SchÃ¼tt et al. (2021)
- Dataset processing leverages the Deep4Chem and Wilkinson photosensitizer databases

## ğŸ“§ Contact

[Your contact information]

## ğŸ”— References

- **PaiNN**: SchÃ¼tt et al., "Equivariant message passing for the prediction of tensorial properties and molecular spectra", ICML 2021
- **PyTorch Geometric**: Fey & Lenssen, "Fast Graph Representation Learning with PyTorch Geometric", 2019

---

**Note**: This project is under active development. Some features may be experimental.
